{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'lbfgs'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/08 21:59:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://localhost:5000/#/experiments/453408896117863994/runs/f960e906d1014a868bca15aee8ba41de\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/453408896117863994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/08 21:59:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://localhost:5000/#/experiments/453408896117863994/runs/d492d81f1f3942f1a2e6e902744dc7a6\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/453408896117863994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/08 21:59:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBClassifier at: http://localhost:5000/#/experiments/453408896117863994/runs/7c56f3f21be345bda4df0b4b45775922\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/453408896117863994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/08 21:59:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/453408896117863994/runs/27d1c8e33aca470089ffd7caf81fec01\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/453408896117863994\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"deployment model\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })  \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Cannot start run with ID f544c611b6cf4c6ea3b1936cb5e2a8be because active run ID does not match environment run ID. Make sure --experiment-name or --experiment-id matches experiment set with set_experiment(), or just use command-line arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m run_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf544c611b6cf4c6ea3b1936cb5e2a8be\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mregister_model(model_uri\u001b[38;5;241m=\u001b[39mmodel_uri, name\u001b[38;5;241m=\u001b[39mmodel_name)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:374\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Check to see if experiment_id from environment matches experiment_id from set_experiment()\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    371\u001b[0m     _active_experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _active_experiment_id \u001b[38;5;241m!=\u001b[39m active_run_obj\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mexperiment_id\n\u001b[0;32m    373\u001b[0m ):\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot start run with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexisting_run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because active run ID \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match environment run ID. Make sure --experiment-name \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor --experiment-id matches experiment set with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_experiment(), or just use command-line arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# Check if the current run has been deleted.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m active_run_obj\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mlifecycle_stage \u001b[38;5;241m==\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mDELETED:\n",
      "\u001b[1;31mMlflowException\u001b[0m: Cannot start run with ID f544c611b6cf4c6ea3b1936cb5e2a8be because active run ID does not match environment run ID. Make sure --experiment-name or --experiment-id matches experiment set with set_experiment(), or just use command-line arguments"
     ]
    }
   ],
   "source": [
    "model_name = 'XGB-Smote'\n",
    "run_id=input('f544c611b6cf4c6ea3b1936cb5e2a8be')\n",
    "model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB-Smote'\n",
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition the Model to Production Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model_uri = f\"models:/{model_name}@appserver\"\n",
    "production_model_name = \"finalproduction\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'production_model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ignore below code\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 4\u001b[0m prod_model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mproduction_model_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@productionserver2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mxgboost\u001b[38;5;241m.\u001b[39mload_model(prod_model_uri)\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'production_model_name' is not defined"
     ]
    }
   ],
   "source": [
    "# ignore below code\n",
    "\n",
    "model_version = 2\n",
    "prod_model_uri = f\"models:/{production_model_name}@productionserver2\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
